{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cdaf0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba6d696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "biometric_final_df=pd.read_csv(\"../Dataset/api_data_aadhar_biometric/aadhar_biometric_final.csv\")\n",
    "demographic_final_df=pd.read_csv(\"../Dataset/api_data_aadhar_demographic/aadhaar_demographic_final.csv\")\n",
    "enrolment_final_df=pd.read_csv(\"../Dataset/api_data_aadhar_enrolment/aadhar_enrolment_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "399d7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [biometric_final_df, demographic_final_df, enrolment_final_df]:\n",
    "    df['join_date'] = pd.to_datetime(\n",
    "        df['date'],\n",
    "        format='mixed',\n",
    "        dayfirst=True,\n",
    "        errors='coerce'\n",
    "    )\n",
    "bio_demo_df = pd.merge(\n",
    "    biometric_final_df,\n",
    "    demographic_final_df,\n",
    "    on=['join_date', 'state', 'district', 'pincode'],\n",
    "    how='outer',\n",
    "    suffixes=('_bio', '_demo')\n",
    ")\n",
    "final_df = pd.merge(\n",
    "    bio_demo_df,\n",
    "    enrolment_final_df,\n",
    "    on=['join_date', 'state', 'district', 'pincode'],\n",
    "    how='outer',\n",
    "    suffixes=('', '_enr')\n",
    ")\n",
    "final_df['date_final'] = (\n",
    "    final_df['date_bio']\n",
    "    .combine_first(final_df['date_demo'])\n",
    "    .combine_first(final_df['date'])\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7cc5d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=final_df.drop(columns=['date_bio','date_final','date','date_demo'],errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb0cc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>bio_age_5_17</th>\n",
       "      <th>bio_age_17_</th>\n",
       "      <th>join_date</th>\n",
       "      <th>demo_age_5_17</th>\n",
       "      <th>demo_age_17_</th>\n",
       "      <th>age_0_5</th>\n",
       "      <th>age_5_17</th>\n",
       "      <th>age_18_greater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>Andamans</td>\n",
       "      <td>744101</td>\n",
       "      <td>16.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>Nicobar</td>\n",
       "      <td>744301</td>\n",
       "      <td>101.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>Nicobar</td>\n",
       "      <td>744302</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>Nicobar</td>\n",
       "      <td>744303</td>\n",
       "      <td>46.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>Nicobar</td>\n",
       "      <td>744304</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         state  district  pincode  bio_age_5_17  bio_age_17_  \\\n",
       "0    Andaman & Nicobar Islands  Andamans   744101          16.0        193.0   \n",
       "1  Andaman and Nicobar Islands   Nicobar   744301         101.0         48.0   \n",
       "2  Andaman and Nicobar Islands   Nicobar   744302          15.0         12.0   \n",
       "3  Andaman and Nicobar Islands   Nicobar   744303          46.0         27.0   \n",
       "4  Andaman and Nicobar Islands   Nicobar   744304          16.0         14.0   \n",
       "\n",
       "   join_date  demo_age_5_17  demo_age_17_  age_0_5  age_5_17  age_18_greater  \n",
       "0 2025-03-01            NaN           NaN      NaN       NaN             NaN  \n",
       "1 2025-03-01           16.0         180.0      NaN       NaN             NaN  \n",
       "2 2025-03-01            NaN           NaN      NaN       NaN             NaN  \n",
       "3 2025-03-01            NaN           NaN      NaN       NaN             NaN  \n",
       "4 2025-03-01            NaN           NaN      NaN       NaN             NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc344688",
   "metadata": {},
   "source": [
    "# State Normalisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2705bc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Andaman & Nicobar Islands', 'Andaman and Nicobar Islands',\n",
       "       'Andhra Pradesh', 'Arunachal Pradesh', 'Assam', 'Bihar',\n",
       "       'Chandigarh', 'Chhattisgarh', 'Dadra & Nagar Haveli',\n",
       "       'Dadra and Nagar Haveli',\n",
       "       'Dadra and Nagar Haveli and Daman and Diu', 'Daman & Diu',\n",
       "       'Daman and Diu', 'Delhi', 'Goa', 'Gujarat', 'Haryana',\n",
       "       'Himachal Pradesh', 'Jammu and Kashmir', 'Jharkhand', 'Karnataka',\n",
       "       'Kerala', 'Ladakh', 'Lakshadweep', 'Madhya Pradesh', 'Maharashtra',\n",
       "       'Manipur', 'Meghalaya', 'Mizoram', 'Nagaland', 'Odisha', 'Orissa',\n",
       "       'Pondicherry', 'Puducherry', 'Punjab', 'Rajasthan', 'Sikkim',\n",
       "       'Tamil Nadu', 'Telangana', 'Tripura', 'Uttar Pradesh',\n",
       "       'Uttarakhand', 'West Bengal',\n",
       "       'The Dadra And Nagar Haveli And Daman And Diu',\n",
       "       'Jammu And Kashmir', 'Jammu & Kashmir', 'ODISHA', 'WEST BENGAL',\n",
       "       'WESTBENGAL', 'West  Bengal', 'West bengal', 'Westbengal',\n",
       "       'andhra pradesh', 'odisha', 'west Bengal', '100000', 'West Bangal',\n",
       "       'Uttaranchal', 'Chhatisgarh', 'West Bengli', 'BALANAGAR',\n",
       "       'Darbhanga', 'Puttenahalli', 'Jaipur', 'Madanapalle', 'Tamilnadu'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"state\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5da8cde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2392273"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22fc14cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique states: 42\n",
      "100000\n",
      "Andaman And Nicobar Islands\n",
      "Andhra Pradesh\n",
      "Arunachal Pradesh\n",
      "Assam\n",
      "Balanagar\n",
      "Bihar\n",
      "Chandigarh\n",
      "Chhattisgarh\n",
      "Dadra And Nagar Haveli And Daman And Diu\n",
      "Darbhanga\n",
      "Delhi\n",
      "Goa\n",
      "Gujarat\n",
      "Haryana\n",
      "Himachal Pradesh\n",
      "Jaipur\n",
      "Jammu And Kashmir\n",
      "Jharkhand\n",
      "Karnataka\n",
      "Kerala\n",
      "Ladakh\n",
      "Lakshadweep\n",
      "Madanapalle\n",
      "Madhya Pradesh\n",
      "Maharashtra\n",
      "Manipur\n",
      "Meghalaya\n",
      "Mizoram\n",
      "Nagaland\n",
      "Odisha\n",
      "Puducherry\n",
      "Punjab\n",
      "Puttenahalli\n",
      "Rajasthan\n",
      "Sikkim\n",
      "Tamil Nadu\n",
      "Telangana\n",
      "Tripura\n",
      "Uttar Pradesh\n",
      "Uttarakhand\n",
      "West Bengal\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Normalize raw state text\n",
    "final_df[\"state\"] = (\n",
    "    final_df[\"state\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.replace(\"&\", \"and\")\n",
    ")\n",
    "\n",
    "# Explicit state corrections (canonical mapping)\n",
    "state_corrections = {\n",
    "\n",
    "    # Andaman & Nicobar\n",
    "    \"andaman and nicobar islands\": \"Andaman and Nicobar Islands\",\n",
    "\n",
    "    # Andhra Pradesh\n",
    "    \"andhra pradesh\": \"Andhra Pradesh\",\n",
    "\n",
    "    # Telangana\n",
    "    \"telangana\": \"Telangana\",\n",
    "    \n",
    "    #Tamil Nadu\n",
    "    \"tamil nadu\": \"Tamil Nadu\",\n",
    "    \"tamilnadu\": \"Tamil Nadu\",\n",
    "\n",
    "    # Bihar\n",
    "    \"bihar\": \"Bihar\",\n",
    "\n",
    "    # Chhattisgarh\n",
    "    \"chhatisgarh\": \"Chhattisgarh\",\n",
    "\n",
    "    # Dadra & Nagar Haveli and Daman & Diu (merged UT)\n",
    "    \"dadra and nagar haveli\": \"Dadra and Nagar Haveli and Daman and Diu\",\n",
    "    \"daman and diu\": \"Dadra and Nagar Haveli and Daman and Diu\",\n",
    "    \"the dadra and nagar haveli and daman and diu\": \"Dadra and Nagar Haveli and Daman and Diu\",\n",
    "\n",
    "    # Delhi\n",
    "    \"delhi\": \"Delhi\",\n",
    "\n",
    "    # Jammu & Kashmir\n",
    "    \"jammu and kashmir\": \"Jammu and Kashmir\",\n",
    "\n",
    "    # Odisha\n",
    "    \"odisha\": \"Odisha\",\n",
    "    \"orissa\": \"Odisha\",\n",
    "\n",
    "    # Puducherry\n",
    "    \"pondicherry\": \"Puducherry\",\n",
    "\n",
    "    # Uttarakhand\n",
    "    \"uttaranchal\": \"Uttarakhand\",\n",
    "\n",
    "    # West Bengal variants\n",
    "    \"west bengal\": \"West Bengal\",\n",
    "    \"west bengli\": \"West Bengal\",\n",
    "    \"west bangal\": \"West Bengal\",\n",
    "    \"westbengal\": \"West Bengal\",\n",
    "}\n",
    "\n",
    "# Apply corrections\n",
    "final_df[\"state\"] = final_df[\"state\"].replace(state_corrections)\n",
    "\n",
    "# Final formatting\n",
    "final_df[\"state\"] = final_df[\"state\"].str.title()\n",
    "\n",
    "# Inspect results\n",
    "unique_states = sorted(final_df[\"state\"].unique())\n",
    "\n",
    "print(\"Total number of unique states:\", len(unique_states))\n",
    "for state in unique_states:\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a81c775c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(final_df['state']==\"100000\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa903230",
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_STATE_VALUES = {\n",
    "    \"Balanagar\",\n",
    "    \"Jaipur\",\n",
    "    \"Darbhanga\",\n",
    "    \"Madanapalle\",\n",
    "    \"Puttenahalli\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "413f040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[\n",
    "    final_df[\"state\"].notna() &\n",
    "    (final_df[\"state\"].str.strip() != \"100000\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78068c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of cleaned states: 36\n",
      "Andaman And Nicobar Islands\n",
      "Andhra Pradesh\n",
      "Arunachal Pradesh\n",
      "Assam\n",
      "Bihar\n",
      "Chandigarh\n",
      "Chhattisgarh\n",
      "Dadra And Nagar Haveli And Daman And Diu\n",
      "Delhi\n",
      "Goa\n",
      "Gujarat\n",
      "Haryana\n",
      "Himachal Pradesh\n",
      "Jammu And Kashmir\n",
      "Jharkhand\n",
      "Karnataka\n",
      "Kerala\n",
      "Ladakh\n",
      "Lakshadweep\n",
      "Madhya Pradesh\n",
      "Maharashtra\n",
      "Manipur\n",
      "Meghalaya\n",
      "Mizoram\n",
      "Nagaland\n",
      "Odisha\n",
      "Puducherry\n",
      "Punjab\n",
      "Rajasthan\n",
      "Sikkim\n",
      "Tamil Nadu\n",
      "Telangana\n",
      "Tripura\n",
      "Uttar Pradesh\n",
      "Uttarakhand\n",
      "West Bengal\n"
     ]
    }
   ],
   "source": [
    "final_df = final_df[~final_df[\"state\"].isin(NON_STATE_VALUES)]\n",
    "unique_states = sorted(final_df[\"state\"].unique())\n",
    "\n",
    "print(\"Total number of cleaned states:\", len(unique_states))\n",
    "for s in unique_states:\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a508b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"../Dataset/GeoJSON/states_districts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    states_districts = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c62901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_district_map = {}\n",
    "\n",
    "for item in states_districts[\"states\"]:\n",
    "    state = item[\"state\"].strip().lower()\n",
    "    districts = {d.strip().lower() for d in item[\"districts\"]}\n",
    "    state_district_map[state] = districts\n",
    "\n",
    "final_df[\"state_norm\"] = (\n",
    "    final_df[\"state\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "final_df[\"district_norm\"] = (\n",
    "    final_df[\"district\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "30d80353",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'state_norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'state_norm'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m district \u001b[38;5;129;01min\u001b[39;00m state_district_map[state]\n\u001b[1;32m---> 10\u001b[0m final_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_valid_district\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m final_df\u001b[38;5;241m.\u001b[39mapply(is_valid_district, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m anomalies_df \u001b[38;5;241m=\u001b[39m final_df[\u001b[38;5;241m~\u001b[39mfinal_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_valid_district\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal anomalies found:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(anomalies_df))\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[52], line 2\u001b[0m, in \u001b[0;36mis_valid_district\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_valid_district\u001b[39m(row):\n\u001b[1;32m----> 2\u001b[0m     state \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m     district \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistrict_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m state_district_map:\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'state_norm'"
     ]
    }
   ],
   "source": [
    "def is_valid_district(row):\n",
    "    state = row[\"state_norm\"]\n",
    "    district = row[\"district_norm\"]\n",
    "\n",
    "    if state not in state_district_map:\n",
    "        return False\n",
    "\n",
    "    return district in state_district_map[state]\n",
    "\n",
    "final_df[\"is_valid_district\"] = final_df.apply(is_valid_district, axis=1)\n",
    "\n",
    "anomalies_df = final_df[~final_df[\"is_valid_district\"]]\n",
    "\n",
    "print(\"Total anomalies found:\", len(anomalies_df))\n",
    "anomalies_df[[\"state\", \"district\"]].drop_duplicates().head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3dbea16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[final_df[\"is_valid_district\"]].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7707fa72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'district', 'pincode', 'bio_age_5_17', 'bio_age_17_',\n",
       "       'join_date', 'demo_age_5_17', 'demo_age_17_', 'age_0_5', 'age_5_17',\n",
       "       'age_18_greater', 'state_norm', 'district_norm', 'is_valid_district'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "022f6fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total anomaly rows: 0\n",
      "Unique anomaly state–district pairs:\n",
      "Empty DataFrame\n",
      "Columns: [state, district]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../Dataset/GeoJSON/states_districts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    states_districts = json.load(f)\n",
    "\n",
    "state_district_map = {\n",
    "    item[\"state\"].strip().lower(): {\n",
    "        d.strip().lower() for d in item[\"districts\"]\n",
    "    }\n",
    "    for item in states_districts[\"states\"]\n",
    "}\n",
    "\n",
    "final_df[\"state_norm\"] = (\n",
    "    final_df[\"state\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "final_df[\"district_norm\"] = (\n",
    "    final_df[\"district\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "def is_valid_district(row):\n",
    "    state = row[\"state_norm\"]\n",
    "    district = row[\"district_norm\"]\n",
    "\n",
    "    if state not in state_district_map:\n",
    "        return False\n",
    "\n",
    "    return district in state_district_map[state]\n",
    "\n",
    "\n",
    "final_df[\"is_valid_district\"] = final_df.apply(is_valid_district, axis=1)\n",
    "\n",
    "anomalies_df = final_df[~final_df[\"is_valid_district\"]]\n",
    "\n",
    "print(\"Total anomaly rows:\", len(anomalies_df))\n",
    "print(\"Unique anomaly state–district pairs:\")\n",
    "print(\n",
    "    anomalies_df[[\"state\", \"district\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values([\"state\", \"district\"])\n",
    "    .head(50)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "106a31ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of districts: 728\n"
     ]
    }
   ],
   "source": [
    "total_districts = final_df[\"district\"].nunique()\n",
    "\n",
    "print(\"Total number of districts:\", total_districts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f268b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         state district  pincode  bio_age_5_17  bio_age_17_  \\\n",
      "1  Andaman And Nicobar Islands  Nicobar   744301         101.0         48.0   \n",
      "2  Andaman And Nicobar Islands  Nicobar   744302          15.0         12.0   \n",
      "\n",
      "   join_date  demo_age_5_17  demo_age_17_  age_0_5  age_5_17  age_18_greater  \\\n",
      "1 2025-03-01           16.0         180.0      NaN       NaN             NaN   \n",
      "2 2025-03-01            NaN           NaN      NaN       NaN             NaN   \n",
      "\n",
      "                    state_norm district_norm  is_valid_district  \n",
      "1  andaman and nicobar islands       nicobar               True  \n",
      "2  andaman and nicobar islands       nicobar               True  \n"
     ]
    }
   ],
   "source": [
    "duplicate_rows = final_df[\n",
    "    final_df.duplicated(subset=[\"state\", \"district\"], keep=False)\n",
    "]\n",
    "\n",
    "print(duplicate_rows.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f12fd3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'district', 'pincode', 'bio_age_5_17', 'bio_age_17_',\n",
       "       'join_date', 'demo_age_5_17', 'demo_age_17_', 'age_0_5', 'age_5_17',\n",
       "       'age_18_greater', 'state_norm', 'district_norm', 'is_valid_district'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fcd2099f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['state', 'district', 'pincode', 'bio_age_5_17', 'bio_age_17_',\n",
      "       'join_date', 'demo_age_5_17', 'demo_age_17_', 'age_0_5', 'age_5_17',\n",
      "       'age_18_greater'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "final_df = final_df.drop(\n",
    "    columns=[\"state_norm\", \"district_norm\", \"is_valid_district\"],\n",
    "    errors=\"ignore\"\n",
    ")\n",
    "print(final_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb21a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.rename(columns={'join_date': 'date','age_0_5':'enr_age_0_5','age_5_17':'enr_age_5_17','age_18_greater':'enr_age_18_greater','demo_age_17_':'demo_age_17_greater','bio_age_17_':'bio_age_17_greater'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b7c4d900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>bio_age_5_17</th>\n",
       "      <th>bio_age_17_greater</th>\n",
       "      <th>date</th>\n",
       "      <th>demo_age_5_17</th>\n",
       "      <th>demo_age_17_greater</th>\n",
       "      <th>enr_age_0_5</th>\n",
       "      <th>enr_age_5_17</th>\n",
       "      <th>enr_age_18_greater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andaman And Nicobar Islands</td>\n",
       "      <td>Nicobar</td>\n",
       "      <td>744301</td>\n",
       "      <td>101.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andaman And Nicobar Islands</td>\n",
       "      <td>Nicobar</td>\n",
       "      <td>744302</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andaman And Nicobar Islands</td>\n",
       "      <td>Nicobar</td>\n",
       "      <td>744303</td>\n",
       "      <td>46.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andaman And Nicobar Islands</td>\n",
       "      <td>Nicobar</td>\n",
       "      <td>744304</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Andaman And Nicobar Islands</td>\n",
       "      <td>North And Middle Andaman</td>\n",
       "      <td>744201</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         state                  district  pincode  \\\n",
       "1  Andaman And Nicobar Islands                   Nicobar   744301   \n",
       "2  Andaman And Nicobar Islands                   Nicobar   744302   \n",
       "3  Andaman And Nicobar Islands                   Nicobar   744303   \n",
       "4  Andaman And Nicobar Islands                   Nicobar   744304   \n",
       "5  Andaman And Nicobar Islands  North And Middle Andaman   744201   \n",
       "\n",
       "   bio_age_5_17  bio_age_17_greater       date  demo_age_5_17  \\\n",
       "1         101.0                48.0 2025-03-01           16.0   \n",
       "2          15.0                12.0 2025-03-01            NaN   \n",
       "3          46.0                27.0 2025-03-01            NaN   \n",
       "4          16.0                14.0 2025-03-01            NaN   \n",
       "5          41.0                40.0 2025-03-01            NaN   \n",
       "\n",
       "   demo_age_17_greater  enr_age_0_5  enr_age_5_17  enr_age_18_greater  \n",
       "1                180.0          NaN           NaN                 NaN  \n",
       "2                  NaN          NaN           NaN                 NaN  \n",
       "3                  NaN          NaN           NaN                 NaN  \n",
       "4                  NaN          NaN           NaN                 NaN  \n",
       "5                  NaN          NaN           NaN                 NaN  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python E Drive",
   "language": "python",
   "name": "edrive"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
